{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL credits ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a importar librerias necesarias, cargar el archivo, configurar vistas de impresiones. Luego visualizaremos la estructura del dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset de créditos\n",
    "credits_df = pd.read_csv('credits.csv')\n",
    "\n",
    "credits_df = credits_df.copy()   # Hacemos una copia para asegurarnos que se guarden los cambios que hagamos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inspeccionará que columnas hay y que tipo de dato tienen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45476 entries, 0 to 45475\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   cast    45476 non-null  object\n",
      " 1   crew    45476 non-null  object\n",
      " 2   id      45476 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n",
      "None\n",
      "cast    0\n",
      "crew    0\n",
      "id      0\n",
      "dtype: int64\n",
      "                cast           crew             id\n",
      "0      <class 'str'>  <class 'str'>  <class 'int'>\n",
      "1      <class 'str'>  <class 'str'>  <class 'int'>\n",
      "2      <class 'str'>  <class 'str'>  <class 'int'>\n",
      "3      <class 'str'>  <class 'str'>  <class 'int'>\n",
      "4      <class 'str'>  <class 'str'>  <class 'int'>\n",
      "...              ...            ...            ...\n",
      "45471  <class 'str'>  <class 'str'>  <class 'int'>\n",
      "45472  <class 'str'>  <class 'str'>  <class 'int'>\n",
      "45473  <class 'str'>  <class 'str'>  <class 'int'>\n",
      "45474  <class 'str'>  <class 'str'>  <class 'int'>\n",
      "45475  <class 'str'>  <class 'str'>  <class 'int'>\n",
      "\n",
      "[45476 rows x 3 columns]\n",
      "Cantidad de tipos de datos únicos por columna:\n",
      "cast    1\n",
      "crew    1\n",
      "id      1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_4560\\3676547377.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  type_data_columns = credits_df[['cast', 'crew', 'id']].applymap(type)\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_4560\\3676547377.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  tipos_por_columna = credits_df.applymap(type).nunique()\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos la información del DataFrame\n",
    "print(credits_df.info())\n",
    "\n",
    "# Verificamos si hay valores nulos\n",
    "print(credits_df.isnull().sum())\n",
    "\n",
    "# Aplicamos type a todos los elementos de las columnas seleccionadas\n",
    "type_data_columns = credits_df[['cast', 'crew', 'id']].applymap(type)\n",
    "\n",
    "# Muestra los tipos de datos de cada elemento en las columnas seleccionadas\n",
    "print(type_data_columns)\n",
    "\n",
    "# Verificamos los tipos de datos de las columnas\n",
    "tipos_por_columna = credits_df.applymap(type).nunique()\n",
    "print(\"Cantidad de tipos de datos únicos por columna:\")\n",
    "print(tipos_por_columna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos a usar el id para nuestro modelo de recomendación, vamos a revisar bien dicha columna para prevenir errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# Verificamos el tipo de dato de la columna 'id'\n",
    "print(type(credits_df['id'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos duplicados\n",
    "credits_df.drop_duplicates(subset='id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que son cadenas que representan listas de dict, se realiza la conversion necesaria para poder extraer la informacion útil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         actor_names     director_names\n",
      "0  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...    [John Lasseter]\n",
      "1  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...     [Joe Johnston]\n",
      "2  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...    [Howard Deutch]\n",
      "3  [Whitney Houston, Angela Bassett, Loretta Devi...  [Forest Whitaker]\n",
      "4  [Steve Martin, Diane Keaton, Martin Short, Kim...    [Charles Shyer]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos columnas 'cast' y 'crew' de string a listas de diccionarios\n",
    "credits_df['cast'] = credits_df['cast'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else None)\n",
    "credits_df['crew'] = credits_df['crew'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else None)\n",
    "\n",
    "# Extraemos nombres de actores en 'cast'\n",
    "credits_df['actor_names'] = credits_df['cast'].apply(lambda x: [actor['name'] for actor in x if 'name' in actor] if x else pd.NA)\n",
    "\n",
    "# Extraemos nombre de los directores en 'crew'\n",
    "credits_df['director_names'] = credits_df['crew'].apply(lambda x: [director['name'] for director in x if director.get('job') == 'Director'] if x else pd.NA)\n",
    "\n",
    "# Visualizamos algunas filas para verificar las transformaciones\n",
    "print(credits_df[['actor_names', 'director_names']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de 'actor_names':\n",
      "actor_names\n",
      "<class 'list'>                           43018\n",
      "<class 'pandas._libs.missing.NAType'>     2414\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tipos de 'director_names':\n",
      "director_names\n",
      "<class 'list'>                           44661\n",
      "<class 'pandas._libs.missing.NAType'>      771\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificamos el tipo de dato en cada fila para 'actor_names' y 'director_names'\n",
    "tipos_actor_names = credits_df['actor_names'].apply(type)\n",
    "tipos_director_names = credits_df['director_names'].apply(type)\n",
    "\n",
    "# Mostramos los tipos\n",
    "print(\"Tipos de 'actor_names':\")\n",
    "print(tipos_actor_names.value_counts())\n",
    "\n",
    "print(\"\\nTipos de 'director_names':\")\n",
    "print(tipos_director_names.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al toparme con valores nulos en las columnas nuevas de actor_names y director_name, como son porcentajes minimos decido excluirlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes en credits_df: 42668\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos filas con valores nulos en 'actor_names' y 'director_names'\n",
    "credits_df.dropna(subset=['actor_names', 'director_names'], inplace=True)\n",
    "\n",
    "# Verificamos cuántas filas quedan después de la eliminación\n",
    "print(f\"Filas restantes en credits_df: {credits_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Contabilizamos los valores nulos en 'actor_names' y 'director_names' luego del proceso\n",
    "nulos_actor_names = credits_df['actor_names'].isna().sum()\n",
    "nulos_director_names = credits_df['director_names'].isna().sum()\n",
    "print(nulos_actor_names)\n",
    "print(nulos_director_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino las columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                        actor_names     director_names\n",
      "0    862  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...    [John Lasseter]\n",
      "1   8844  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...     [Joe Johnston]\n",
      "2  15602  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...    [Howard Deutch]\n",
      "3  31357  [Whitney Houston, Angela Bassett, Loretta Devi...  [Forest Whitaker]\n",
      "4  11862  [Steve Martin, Diane Keaton, Martin Short, Kim...    [Charles Shyer]\n"
     ]
    }
   ],
   "source": [
    "credits_df.drop(columns=['cast', 'crew'], inplace=True)\n",
    "\n",
    "# Verificamos el nuevo DataFrame\n",
    "print(credits_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se finaliza el proceso de transformaciones necesarias, se guarda el nuevo data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df.to_csv('credits_ok.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la unión de ambos data set limpios para disponer de toda la información junta para las consultas de la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      budget      id                                           overview  \\\n",
      "0          0  253292  a comedic, brutally honest documentary followi...   \n",
      "1          0  156268  a no-nonsense cop has a flair for fashion and ...   \n",
      "2          0   68297  the documentary recounts the world's first nuc...   \n",
      "3  150000000     809  shrek, fiona and donkey set off to far, far aw...   \n",
      "4          0  171795  a behind the scenes look into george romero's ...   \n",
      "\n",
      "   popularity release_date      revenue                     title  \\\n",
      "0    2.811629   2014-03-08          0.0                harmontown   \n",
      "1    3.097025   2013-03-22        228.0      inappropriate comedy   \n",
      "2    1.127808   2005-08-05          0.0                 hiroshima   \n",
      "3   16.229860   2004-05-19  919838758.0                   shrek 2   \n",
      "4    1.452115   2013-10-18          0.0  birth of the living dead   \n",
      "\n",
      "   vote_average  vote_count   collection_name  \\\n",
      "0           6.9        37.0     sin colección   \n",
      "1           3.6        31.0     sin colección   \n",
      "2           6.2        13.0     sin colección   \n",
      "3           6.7      3082.0  shrek collection   \n",
      "4           6.6        22.0     sin colección   \n",
      "\n",
      "                                         genre_names  \\\n",
      "0                                    ['documentary']   \n",
      "1                                         ['comedy']   \n",
      "2                           ['documentary', 'drama']   \n",
      "3  ['adventure', 'animation', 'comedy', 'family',...   \n",
      "4                                    ['documentary']   \n",
      "\n",
      "                                     companies_names  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2         ['british broadcasting corporation (bbc)']   \n",
      "3  ['dreamworks skg', 'pacific data images (pdi)'...   \n",
      "4      ['glass eye pix', 'predestinate productions']   \n",
      "\n",
      "                countries_names   spoken_language_names  release_year  \\\n",
      "0                            []             ['english']        2014.0   \n",
      "1                            []  ['english', 'deutsch']        2013.0   \n",
      "2            ['united kingdom']      ['english', '日本語']        2005.0   \n",
      "3  ['united states of america']             ['english']        2004.0   \n",
      "4  ['united states of america']             ['english']        2013.0   \n",
      "\n",
      "     return  \n",
      "0  0.000000  \n",
      "1  0.000000  \n",
      "2  0.000000  \n",
      "3  6.132258  \n",
      "4  0.000000  \n",
      "      id                                        actor_names  \\\n",
      "0    862  ['Tom Hanks', 'Tim Allen', 'Don Rickles', 'Jim...   \n",
      "1   8844  ['Robin Williams', 'Jonathan Hyde', 'Kirsten D...   \n",
      "2  15602  ['Walter Matthau', 'Jack Lemmon', 'Ann-Margret...   \n",
      "3  31357  ['Whitney Houston', 'Angela Bassett', 'Loretta...   \n",
      "4  11862  ['Steve Martin', 'Diane Keaton', 'Martin Short...   \n",
      "\n",
      "        director_names  \n",
      "0    ['John Lasseter']  \n",
      "1     ['Joe Johnston']  \n",
      "2    ['Howard Deutch']  \n",
      "3  ['Forest Whitaker']  \n",
      "4    ['Charles Shyer']  \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el nuevo dataset de movies \n",
    "movies_ok = pd.read_csv('movies_ok.csv')  \n",
    "\n",
    "#Cargamos el nuevo dataset de credits\n",
    "credits_ok = pd.read_csv('credits_ok.csv')\n",
    "\n",
    "# Verifica que se haya cargado correctamente\n",
    "print(movies_ok.head())\n",
    "print(credits_ok.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeamos el tamaño del dataframe antes de hacer la unión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42668, 3)\n"
     ]
    }
   ],
   "source": [
    "print(credits_ok.shape) #chequeamos tamaño de df antes de filtrarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      budget      id                                           overview  \\\n",
      "0          0  253292  a comedic, brutally honest documentary followi...   \n",
      "1          0  156268  a no-nonsense cop has a flair for fashion and ...   \n",
      "2          0   68297  the documentary recounts the world's first nuc...   \n",
      "3  150000000     809  shrek, fiona and donkey set off to far, far aw...   \n",
      "4          0  171795  a behind the scenes look into george romero's ...   \n",
      "\n",
      "   popularity release_date      revenue                     title  \\\n",
      "0    2.811629   2014-03-08          0.0                harmontown   \n",
      "1    3.097025   2013-03-22        228.0      inappropriate comedy   \n",
      "2    1.127808   2005-08-05          0.0                 hiroshima   \n",
      "3   16.229860   2004-05-19  919838758.0                   shrek 2   \n",
      "4    1.452115   2013-10-18          0.0  birth of the living dead   \n",
      "\n",
      "   vote_average  vote_count   collection_name  \\\n",
      "0           6.9        37.0     sin colección   \n",
      "1           3.6        31.0     sin colección   \n",
      "2           6.2        13.0     sin colección   \n",
      "3           6.7      3082.0  shrek collection   \n",
      "4           6.6        22.0     sin colección   \n",
      "\n",
      "                                         genre_names  \\\n",
      "0                                    ['documentary']   \n",
      "1                                         ['comedy']   \n",
      "2                           ['documentary', 'drama']   \n",
      "3  ['adventure', 'animation', 'comedy', 'family',...   \n",
      "4                                    ['documentary']   \n",
      "\n",
      "                                     companies_names  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2         ['british broadcasting corporation (bbc)']   \n",
      "3  ['dreamworks skg', 'pacific data images (pdi)'...   \n",
      "4      ['glass eye pix', 'predestinate productions']   \n",
      "\n",
      "                countries_names   spoken_language_names  release_year  \\\n",
      "0                            []             ['english']        2014.0   \n",
      "1                            []  ['english', 'deutsch']        2013.0   \n",
      "2            ['united kingdom']      ['english', '日本語']        2005.0   \n",
      "3  ['united states of america']             ['english']        2004.0   \n",
      "4  ['united states of america']             ['english']        2013.0   \n",
      "\n",
      "     return                                        actor_names  \\\n",
      "0  0.000000  ['Dan Harmon', 'Erin McGathy', 'Spencer Critte...   \n",
      "1  0.000000  ['Rob Schneider', 'Michelle Rodriguez', 'Adrie...   \n",
      "2  0.000000  ['John Hurt', 'Shuntaro Hida', 'Robert Austin'...   \n",
      "3  6.132258  ['Mike Myers', 'Eddie Murphy', 'Cameron Diaz',...   \n",
      "4  0.000000                               ['George A. Romero']   \n",
      "\n",
      "                                      director_names  \n",
      "0                                  ['Neil Berkeley']  \n",
      "1                                    ['Vince Offer']  \n",
      "2                                ['Paul Wilmshurst']  \n",
      "3  ['Andrew Adamson', 'Kelly Asbury', 'Conrad Ver...  \n",
      "4                                      ['Rob Kuhns']  \n"
     ]
    }
   ],
   "source": [
    "# Unir el DataFrame de credits con el de movies\n",
    "merged_df = movies_ok.merge(credits_ok, on='id', how='left')\n",
    "\n",
    "# Verificamos el nuevo DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos que efectivamente se redujo el tamaño del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 18)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape) #chequeamos tamaño de df antes de filtrarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el modelo de recomendación, necesitaremos unificar en una sola columna, las columnas de género, director y país. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una copia del DataFrame, es buena practica.\n",
    "merged_df = merged_df.copy()\n",
    "\n",
    "# Convertimos cada lista en una cadena de texto\n",
    "merged_df['genre_names'] = merged_df['genre_names'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "merged_df['director_names'] = merged_df['director_names'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "merged_df['countries_names'] = merged_df['countries_names'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "#Creamos la columna combinada \n",
    "merged_df['features'] = merged_df['genre_names'] + \" \" + merged_df['director_names'] + \" \" + merged_df['countries_names']\n",
    "\n",
    "#Manejo de Nan\n",
    "merged_df['features'] = merged_df['features'].fillna('')   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesito crear una columna nueva para guardar el escalado de vote_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "merged_df['vote_average_scaled'] = scaler.fit_transform(merged_df[['vote_average']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, convertimos el archivo a parquet porque es una excelente idea para optimizar el almacenamiento y lectura de datos en la API y guardamos el nuevo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardamos el nuevo dataset \n",
    "merged_df.to_parquet(\"dataset_ok.parquet\", index=False)\n",
    "\n",
    "merged_df.to_csv(\"dataset_ok.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
